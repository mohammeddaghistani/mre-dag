import streamlit as st
import pandas as pd
import numpy as np
import pydeck as pdk
from streamlit_gsheets import GSheetsConnection

from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score

from io import BytesIO
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas

# =========================
# 0) Ø«ÙˆØ§Ø¨Øª Ù…ÙƒØ© + Ø£Ø¯ÙˆØ§Øª
# =========================
CITY_NAME = "Ù…ÙƒØ© Ø§Ù„Ù…ÙƒØ±Ù…Ø©"
HARAM_LAT = 21.4225
HARAM_LON = 39.8262

def haversine_km_np(lat, lon, lat2, lon2):
    """Vectorized Haversine distance in KM (lat/lon arrays)."""
    R = 6371.0
    lat = np.radians(lat.astype(float))
    lon = np.radians(lon.astype(float))
    lat2 = np.radians(float(lat2))
    lon2 = np.radians(float(lon2))
    dlat = lat2 - lat
    dlon = lon2 - lon
    a = np.sin(dlat/2)**2 + np.cos(lat)*np.cos(lat2)*np.sin(dlon/2)**2
    return 2 * R * np.arcsin(np.sqrt(a))

def gov_confidence(similar_count: int, r2v: float) -> tuple[str, int]:
    # Ù†Ù‚Ø§Ø· Ø¹Ù„Ù‰ 100: (60 Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø©) + (40 Ù„Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬)
    count_score = min(60, similar_count * 3)      # 20 ØµÙÙ‚Ø© ~ 60
    r2_pts = int(np.clip(r2v, 0, 1) * 40)         # 0..40
    score = int(count_score + r2_pts)
    if score >= 75:
        return "High", score
    elif score >= 50:
        return "Medium", score
    return "Low", score

def build_pdf_report(payload: dict) -> bytes:
    """PDF Ø¨Ø³ÙŠØ· Ø±Ø³Ù…ÙŠ (Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ/Ø£Ø±Ù‚Ø§Ù…) Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙˆØ§ÙÙ‚ Ø¨Ø¯ÙˆÙ† Ø®Ø·ÙˆØ· Ø¹Ø±Ø¨ÙŠØ©."""
    buffer = BytesIO()
    c = canvas.Canvas(buffer, pagesize=A4)
    w, h = A4

    y = h - 60
    c.setFont("Helvetica-Bold", 16)
    c.drawString(50, y, "Estidama | Smart Real Estate Valuation")
    y -= 25
    c.setFont("Helvetica", 12)
    c.drawString(50, y, "Makkah Al-Mukarramah - Preliminary AI Valuation Report (2026)")
    y -= 30

    c.setFont("Helvetica", 11)
    for k, v in payload.items():
        c.drawString(50, y, f"{k}: {v}")
        y -= 18
        if y < 80:
            c.showPage()
            y = h - 60
            c.setFont("Helvetica", 11)

    c.setFont("Helvetica-Oblique", 9)
    c.drawString(50, 50, "Disclaimer: Automated estimate based on available transactions; subject to official review.")
    c.showPage()
    c.save()

    buffer.seek(0)
    return buffer.getvalue()

@st.cache_resource
def train_makkah_model(df: pd.DataFrame):
    X = df[['area', 'lat', 'lon', 'dist_haram_km']]
    y = df['price']

    # Ø­Ù…Ø§ÙŠØ©: Ø¥Ù† ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ù„ÙŠÙ„Ø© Ø¬Ø¯Ù‹Ø§
    if len(df) < 20:
        # Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø³ÙŠØ· Ø¬Ø¯Ù‹Ø§ Ù„ØªÙØ§Ø¯ÙŠ Ø§Ù†Ù‡ÙŠØ§Ø± Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        model = GradientBoostingRegressor(random_state=42)
        model.fit(X, y)
        return model, 0.0

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    model = GradientBoostingRegressor(
        n_estimators=300,
        learning_rate=0.04,
        max_depth=4,
        random_state=42
    )
    model.fit(X_train, y_train)

    score = r2_score(y_test, model.predict(X_test))
    return model, float(score)

# =========================
# 1) Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© + CSS
# =========================
st.set_page_config(
    page_title="Ø¥Ø³ØªØ¯Ø§Ù…Ø© | Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠ Ø§Ù„Ø°ÙƒÙŠ - Ù…ÙƒØ©",
    layout="wide",
    initial_sidebar_state="collapsed"
)

st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Tajawal:wght@400;700&display=swap');
html, body, [class*="css"] { font-family: 'Tajawal', sans-serif; text-align: right; }
.main { background-color: #f4f7f6; }
.stMetric { background: white; padding: 20px; border-radius: 15px; box-shadow: 0 4px 15px rgba(0,0,0,0.05); border-top: 4px solid #c5a059; }
.report-card { background: white; padding: 25px; border-radius: 18px; box-shadow: 0 8px 30px rgba(0,0,0,0.08); margin-bottom: 25px; border-right: 10px solid #1a1a1a; }
.gold-text { color: #c5a059; font-weight: bold; }
.stButton>button { background: linear-gradient(135deg, #1a1a1a 0%, #333 100%); color: #c5a059; border: 1px solid #c5a059; border-radius: 12px; height: 3.5rem; font-size: 1.1rem; transition: 0.3s; }
.stButton>button:hover { transform: translateY(-3px); box-shadow: 0 5px 15px rgba(197, 160, 89, 0.3); color: white; }
</style>
""", unsafe_allow_html=True)

# =========================
# 2) Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªÙ†Ø¸ÙŠÙÙ‡Ø§
# =========================
conn = st.connection("gsheets", type=GSheetsConnection)

@st.cache_data(ttl=60)
def get_clean_data():
    df = conn.read(worksheet="Deals_DB")

    # ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    required_cols = ['latitude', 'longitude', 'Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø³Ù†ÙˆÙŠØ©', 'Ø§Ù„Ù…Ø³Ø§Ø­Ø©', 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©']
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        raise ValueError(f"Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø´ÙŠØª: {missing}")

    df['lat'] = pd.to_numeric(df['latitude'], errors='coerce')
    df['lon'] = pd.to_numeric(df['longitude'], errors='coerce')
    df['price'] = pd.to_numeric(df['Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø³Ù†ÙˆÙŠØ©'], errors='coerce')
    df['area'] = pd.to_numeric(df['Ø§Ù„Ù…Ø³Ø§Ø­Ø©'], errors='coerce')

    df = df.dropna(subset=['lat', 'lon', 'price', 'area', 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©']).copy()

    # ÙÙ„ØªØ±Ø© Ù‚ÙŠÙ… ØºÙŠØ± Ù…Ù†Ø·Ù‚ÙŠØ© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ø­ÙƒÙˆÙ…ÙŠ)
    df = df[(df['area'] > 0) & (df['price'] > 0)].copy()

    # Ù…Ø³Ø§ÙØ© Ø§Ù„Ø­Ø±Ù… (ÙƒÙ…) - Vectorized
    df['dist_haram_km'] = haversine_km_np(df['lat'].to_numpy(), df['lon'].to_numpy(), HARAM_LAT, HARAM_LON)

    return df

try:
    data = get_clean_data()

    # =========================
    # 3) Ù‚ÙÙ„ Ù…ÙƒØ© Ø§Ù„Ù…ÙƒØ±Ù…Ø©
    # =========================
    city_data = data[data['Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©'] == CITY_NAME].copy()
    if city_data.empty:
        st.error("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù…Ø¯ÙŠÙ†Ø© Ù…ÙƒØ© Ø§Ù„Ù…ÙƒØ±Ù…Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ø´ÙŠØª (Deals_DB).")
        st.stop()

    # ØªØ¯Ø±ÙŠØ¨ ML Ø¹Ù„Ù‰ Ù…ÙƒØ©
    model, model_score = train_makkah_model(city_data)

    # ÙˆØ§Ø¬Ù‡Ø© Ø±Ø¦ÙŠØ³ÙŠØ©
    st.markdown(f"""
        <h1 style='text-align: center; color: #1a1a1a;'>
        ğŸ›ï¸ Ù…Ù†ØµØ© <span class='gold-text'>Ø¥Ø³ØªØ¯Ø§Ù…Ø©</span> Ù„Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠ
        <br><span style='font-size:0.85em; color:#444;'>Ù…Ø¯ÙŠÙ†Ø© Ù…ÙƒØ© Ø§Ù„Ù…ÙƒØ±Ù…Ø©</span>
        </h1>
    """, unsafe_allow_html=True)

    st.markdown("""
        <p style='text-align: center; color: #666;'>
        Ù†Ø¸Ø§Ù… Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ© ÙˆÙ…Ø¹Ø§ÙŠÙŠØ± 2026
        </p>
    """, unsafe_allow_html=True)

    tab1, tab2, tab3 = st.tabs(["ğŸ¯ Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… (ML)", "ğŸ—ºï¸ Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©", "ğŸ“Š Ø¨Ù†Ùƒ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙƒØ©"])

    # =========================
    # TAB 1: Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
    # =========================
    with tab1:
        col_input, col_res = st.columns([1, 1.2], gap="large")

        with col_input:
            st.markdown("<div class='report-card'>", unsafe_allow_html=True)
            st.subheader("ğŸ“ Ù…ÙˆØ§ØµÙØ§Øª Ø§Ù„Ø¹Ù‚Ø§Ø± Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù (Ù…ÙƒØ©)")

            target_area = st.number_input("Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ© (Ù…2)", min_value=1, value=500)

            st.markdown("---")
            st.write("ğŸ“ˆ **Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ù†ÙˆØ¹ÙŠØ© (1-5)**")
            q_loc = st.select_slider("Ù‚ÙˆØ© Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ", options=[1, 2, 3, 4, 5], value=3)
            q_spec = st.select_slider("Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª Ø§Ù„ÙÙ†ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø´Ø§Ø¦ÙŠØ©", options=[1, 2, 3, 4, 5], value=3)
            q_age = st.select_slider("Ø¹Ù…Ø± Ø§Ù„Ø¹Ù‚Ø§Ø± ÙˆØ­Ø§Ù„ØªÙ‡", options=[1, 2, 3, 4, 5], value=3)

            # Ø§Ø®ØªÙŠØ§Ø±ÙŠ: Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙˆÙ‚Ø¹ ØªÙ‚Ø±ÙŠØ¨ÙŠ Ø¯Ø§Ø®Ù„ Ù…ÙƒØ© (Ù„Ø±ÙØ¹ Ø¯Ù‚Ø© Ù‚Ø±Ø¨ Ø§Ù„Ø­Ø±Ù…)
            st.markdown("---")
            st.write("ğŸ“ **Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø§Ù„Ø¹Ù‚Ø§Ø± (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„ØªØ­Ø³ÙŠÙ† Ù‚Ø±Ø¨ Ø§Ù„Ø­Ø±Ù…)**")
            use_custom_loc = st.checkbox("Ø³Ø£Ø¯Ø®Ù„ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø§Ù„Ø¹Ù‚Ø§Ø±", value=False)
            if use_custom_loc:
                target_lat = st.number_input("Latitude", value=float(city_data['lat'].mean()), format="%.6f")
                target_lon = st.number_input("Longitude", value=float(city_data['lon'].mean()), format="%.6f")
            else:
                target_lat = float(city_data['lat'].mean())
                target_lon = float(city_data['lon'].mean())

            if st.button("Ø¥ØµØ¯Ø§Ø± Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙ‚Ø¯ÙŠØ±ÙŠ (Ù…ÙƒØ©)"):
                # ØµÙÙ‚Ø§Øª Ù…Ø´Ø§Ø¨Ù‡Ø© Ø¨Ø§Ù„Ù…Ø³Ø§Ø­Ø© (Ù„Ù„Ø«Ù‚Ø© Ø§Ù„Ø­ÙƒÙˆÙ…ÙŠØ©)
                similar = city_data[city_data['area'].between(target_area * 0.8, target_area * 1.2)]
                similar_count = int(len(similar))

                # Ù…ØªÙˆØ³Ø· Ø³Ø¹Ø±ÙŠ Ù…Ø±Ø¬Ø¹ÙŠ (Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© ÙÙ‚Ø·)
                sqm_rate = city_data['price'] / city_data['area']
                base_avg = float(sqm_rate.mean())

                # ØªØ¹Ø¯ÙŠÙ„ Ø¬ÙˆØ¯Ø© (Ù…Ù‚ÙŠØ¯)
                adj = (
                    (q_loc - 3) * 0.04 +
                    (q_spec - 3) * 0.035 +
                    (q_age - 3) * 0.025
                )
                adj = float(np.clip(adj, -0.12, 0.12))
                quality_rate = base_avg * (1 + adj)

                # ML: Ù‚Ø±Ø¨ Ø§Ù„Ø­Ø±Ù… ÙƒÙ€ Feature
                target_dist = float(haversine_km_np(np.array([target_lat]), np.array([target_lon]), HARAM_LAT, HARAM_LON)[0])

                ml_prediction = float(model.predict([[
                    target_area,
                    target_lat,
                    target_lon,
                    target_dist
                ]])[0])

                # Ø«Ù‚Ø© Ø­ÙƒÙˆÙ…ÙŠØ©
                conf_label, conf_score = gov_confidence(similar_count, model_score)

                with col_res:
                    st.markdown("<div class='report-card'>", unsafe_allow_html=True)
                    st.markdown("### ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ (Ù…ÙƒØ©)")

                    r1, r2 = st.columns(2)
                    r1.metric("ØªÙ‚Ø¯ÙŠØ± Ù…Ø±Ø¬Ø¹ÙŠ (Ø³Ø¹Ø±/Ù… Ø¨Ø¹Ø¯ Ø§Ù„Ø¬ÙˆØ¯Ø©)", f"{quality_rate:,.2f} Ø±ÙŠØ§Ù„/Ù…Â²")
                    r2.metric("ØªÙ‚Ø¯ÙŠØ± Ø³Ù†ÙˆÙŠ Ù…Ø±Ø¬Ø¹ÙŠ", f"{(quality_rate * target_area):,.0f} Ø±ÙŠØ§Ù„")

                    st.markdown("---")
                    r3, r4 = st.columns(2)
                    r3.metric("Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø³Ù†ÙˆÙŠØ© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (ML)", f"{ml_prediction:,.0f} Ø±ÙŠØ§Ù„")
                    r4.metric("Ù‚Ø±Ø¨ Ø§Ù„Ø­Ø±Ù…", f"{target_dist:.2f} ÙƒÙ…")

                    st.markdown("---")
                    st.metric("Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø­ÙƒÙˆÙ…ÙŠ", conf_label)
                    st.progress(conf_score / 100)
                    st.caption(f"Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø©: {conf_score}/100 | ØµÙÙ‚Ø§Øª Ù…Ø´Ø§Ø¨Ù‡Ø© Ø¨Ø§Ù„Ù…Ø³Ø§Ø­Ø©: {similar_count} | Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ RÂ²: {round(model_score, 2)}")

                    st.markdown("---")
                    st.write(f"ğŸ§¾ ØªÙ… Ø§Ù„Ø­Ø³Ø§Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª **{len(city_data)}** ØµÙÙ‚Ø© Ø¯Ø§Ø®Ù„ **Ù…ÙƒØ© Ø§Ù„Ù…ÙƒØ±Ù…Ø©**.")

                    # PDF
                    report_payload = {
                        "City": "Makkah Al-Mukarramah",
                        "Target Area (sqm)": target_area,
                        "AI Predicted Annual Value (SAR)": f"{ml_prediction:,.0f}",
                        "Reference Annual Value (SAR)": f"{(quality_rate * target_area):,.0f}",
                        "Distance to Haram (km)": round(target_dist, 2),
                        "Gov Confidence": f"{conf_label} ({conf_score}/100)",
                        "Model R2": round(model_score, 2),
                        "Comparable Deals (Area Similar)": similar_count,
                        "Deals Count (Makkah)": len(city_data),
                        "Quality Location (1-5)": q_loc,
                        "Quality Specs (1-5)": q_spec,
                        "Quality Age (1-5)": q_age,
                    }

                    pdf_bytes = build_pdf_report(report_payload)
                    st.download_button(
                        "â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± PDF",
                        data=pdf_bytes,
                        file_name="Estidama_Makkah_AI_Report.pdf",
                        mime="application/pdf"
                    )

                    st.markdown("</div>", unsafe_allow_html=True)

            st.markdown("</div>", unsafe_allow_html=True)

    # =========================
    # TAB 2: Ø®Ø±ÙŠØ·Ø© ØªÙØ§Ø¹Ù„ÙŠØ©
    # =========================
    with tab2:
        st.subheader("ğŸ“ Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬ØºØ±Ø§ÙÙŠ Ù„Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ø© Ø¯Ø§Ø®Ù„ Ù…ÙƒØ© Ø§Ù„Ù…ÙƒØ±Ù…Ø©")

        view_state = pdk.ViewState(
            latitude=float(city_data['lat'].mean()),
            longitude=float(city_data['lon'].mean()),
            zoom=12,
            pitch=45
        )

        # Ù„ÙˆÙ† Ø¢Ù…Ù† Ø¨Ø¯ÙˆÙ† Ù‚ÙŠÙ… Ø³Ø§Ù„Ø¨Ø©: Ù†Ø¹ØªÙ…Ø¯ ØªØ·Ø¨ÙŠØ¹ Ø¨Ø³ÙŠØ· Ø¹Ù„Ù‰ Ù†Ø·Ø§Ù‚ Ø§Ù„Ø£Ø³Ø¹Ø§Ø±
        p_min = float(city_data['price'].min())
        p_max = float(city_data['price'].max())
        denom = (p_max - p_min) if (p_max - p_min) != 0 else 1.0

        city_data = city_data.copy()
        city_data['price_norm'] = (city_data['price'] - p_min) / denom

        layer = pdk.Layer(
            "ColumnLayer",
            data=city_data,
            get_position="[lon, lat]",
            get_elevation="price / 100",
            radius=100,
            get_fill_color="[255, 255*(1-price_norm), 0, 140]",
            pickable=True,
            auto_highlight=True,
        )

        tooltip_text = "Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø³Ù†ÙˆÙŠØ©: {Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø³Ù†ÙˆÙŠØ©}\nØ§Ù„Ù…Ø³Ø§Ø­Ø©: {Ø§Ù„Ù…Ø³Ø§Ø­Ø©}\nÙ‚Ø±Ø¨ Ø§Ù„Ø­Ø±Ù… (ÙƒÙ…): {dist_haram_km}"
        if 'Ø§Ø³Ù… Ø§Ù„Ù…Ø´Ø±ÙˆØ¹' in city_data.columns:
            tooltip_text = "Ø§Ù„Ù…Ø´Ø±ÙˆØ¹: {Ø§Ø³Ù… Ø§Ù„Ù…Ø´Ø±ÙˆØ¹}\n" + tooltip_text

        st.pydeck_chart(
            pdk.Deck(layers=[layer], initial_view_state=view_state, tooltip={"text": tooltip_text})
        )

    # =========================
    # TAB 3: Ø¨Ù†Ùƒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    # =========================
    with tab3:
        st.subheader("ğŸ“Š Ø³Ø¬Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙƒØ© Ø§Ù„Ù…ÙƒØ±Ù…Ø©")
        drop_cols = [c for c in ['lat', 'lon', 'price_norm'] if c in city_data.columns]
        st.dataframe(city_data.drop(drop_cols, axis=1), use_container_width=True)

except Exception as e:
    st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª ÙÙŠ Ø§Ù„Ø´ÙŠØª (latitude/longitude) ÙˆØ¨Ø§Ù‚ÙŠ Ø§Ù„Ø­Ù‚ÙˆÙ„: {e}")

st.markdown("<br><hr><center>Ø¥Ø³ØªØ¯Ø§Ù…Ø© | ØªØ·ÙˆÙŠØ±: Ù…Ø­Ù…Ø¯ Ø¯Ø§ØºØ³ØªØ§Ù†ÙŠ 2026 Â©</center>", unsafe_allow_html=True)
