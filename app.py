import streamlit as st
import pandas as pd
import numpy as np
import pydeck as pdk

# ML
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score

# Utils
import math
import uuid
from datetime import datetime
from io import BytesIO
from tempfile import NamedTemporaryFile

# PDF + Arabic
from fpdf import FPDF
import arabic_reshaper
from bidi.algorithm import get_display

# QR
import qrcode
from PIL import Image

# =========================
# CONFIG
# =========================
CITY_NAME = "Ù…ÙƒØ© Ø§Ù„Ù…ÙƒØ±Ù…Ø©"
HARAM_LAT = 21.4225
HARAM_LON = 39.8262
FONT_PATH = "Tajawal-Regular.ttf"  # Ù„Ø§Ø²Ù… ÙŠÙƒÙˆÙ† Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø¬Ø§Ù†Ø¨ app.py

REQUIRED_COLS = ["latitude", "longitude", "Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø³Ù†ÙˆÙŠØ©", "Ø§Ù„Ù…Ø³Ø§Ø­Ø©", "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"]

# =========================
# UI SETUP
# =========================
st.set_page_config(
    page_title="Ø¥Ø³ØªØ¯Ø§Ù…Ø© | Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠ â€“ Ù…ÙƒØ©",
    layout="wide",
    initial_sidebar_state="collapsed",
)

st.markdown("""
<style>
html, body, [class*="css"] { text-align: right; }
.gold { color:#c5a059; font-weight:bold; }
.card { background:#fff; padding:18px; border-radius:14px; box-shadow:0 6px 18px rgba(0,0,0,0.06); }
</style>
""", unsafe_allow_html=True)

# =========================
# HELPERS
# =========================
def ar(s: str) -> str:
    return get_display(arabic_reshaper.reshape(str(s)))

def haversine_km(lat1, lon1, lat2, lon2):
    R = 6371.0
    p1, p2 = math.radians(lat1), math.radians(lat2)
    dphi = math.radians(lat2 - lat1)
    dlmb = math.radians(lon2 - lon1)
    a = math.sin(dphi/2)**2 + math.cos(p1)*math.cos(p2)*math.sin(dlmb/2)**2
    return 2 * R * math.asin(math.sqrt(a))

def make_report_id():
    return f"MK-{datetime.now().strftime('%Y%m%d')}-{uuid.uuid4().hex[:6].upper()}"

def gov_confidence(similar_count: int, r2v: float) -> tuple[str, int]:
    score = min(60, similar_count * 3) + int(np.clip(r2v, 0, 1) * 40)
    if score >= 75:
        return "High", score
    if score >= 50:
        return "Medium", score
    return "Low", score

def clean_df(df: pd.DataFrame) -> pd.DataFrame:
    missing = [c for c in REQUIRED_COLS if c not in df.columns]
    if missing:
        raise ValueError(f"Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†Ø§Ù‚ØµØ© ÙÙŠ Ø§Ù„Ù…Ù„Ù: {missing}")

    df = df.copy()
    df["lat"] = pd.to_numeric(df["latitude"], errors="coerce")
    df["lon"] = pd.to_numeric(df["longitude"], errors="coerce")
    df["price"] = pd.to_numeric(df["Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø³Ù†ÙˆÙŠØ©"], errors="coerce")
    df["area"] = pd.to_numeric(df["Ø§Ù„Ù…Ø³Ø§Ø­Ø©"], errors="coerce")

    df = df.dropna(subset=["lat", "lon", "price", "area", "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"]).copy()
    df = df[(df["price"] > 0) & (df["area"] > 0)].copy()

    # Ù‚ÙÙ„ Ù…ÙƒØ©
    df = df[df["Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"] == CITY_NAME].copy()

    if df.empty:
        return df

    # dist to Haram
    df["dist_haram_km"] = np.sqrt(0)  # placeholder
    df["dist_haram_km"] = df.apply(
        lambda r: haversine_km(r["lat"], r["lon"], HARAM_LAT, HARAM_LON),
        axis=1,
    )
    return df

@st.cache_resource
def train_model(df: pd.DataFrame):
    X = df[["area", "lat", "lon", "dist_haram_km"]]
    y = df["price"]

    # Ø¥Ø°Ø§ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ù„ÙŠÙ„Ø© Ø¬Ø¯Ù‹Ø§
    if len(df) < 25:
        model = GradientBoostingRegressor(random_state=42)
        model.fit(X, y)
        return model, 0.0

    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=42)
    model = GradientBoostingRegressor(
        n_estimators=300,
        learning_rate=0.04,
        max_depth=4,
        random_state=42,
    )
    model.fit(Xtr, ytr)
    r2v = r2_score(yte, model.predict(Xte))
    return model, float(r2v)

class GovPDF(FPDF):
    pass

def build_pdf_report(report: dict, verify_url: str) -> bytes:
    # QR image -> temp file (fpdf2 ÙŠØ­Ø¨ Ø§Ù„Ù…Ø³Ø§Ø±)
    qr_img = qrcode.make(verify_url)
    tmp = NamedTemporaryFile(delete=False, suffix=".png")
    qr_img.save(tmp.name)

    pdf = GovPDF(orientation="P", unit="mm", format="A4")
    pdf.add_page()

    # Arabic font
    pdf.add_font("Tajawal", "", FONT_PATH, uni=True)
    pdf.set_font("Tajawal", size=14)

    # Watermark (Ù†Ø³Ø®Ø© Ø£ÙˆÙ„ÙŠØ©)
    pdf.set_text_color(200, 200, 200)
    pdf.set_font("Tajawal", size=42)
    pdf.rotate(25, x=60, y=180)
    pdf.text(25, 160, ar("Ù†Ø³Ø®Ø© Ø£ÙˆÙ„ÙŠØ©"))
    pdf.rotate(0)

    # Header
    pdf.set_text_color(20, 20, 20)
    pdf.set_font("Tajawal", size=16)
    pdf.cell(0, 10, ar("Ù…Ù†ØµØ© Ø¥Ø³ØªØ¯Ø§Ù…Ø© Ù„Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠ Ø§Ù„Ø°ÙƒÙŠ â€“ Ù…ÙƒØ© Ø§Ù„Ù…ÙƒØ±Ù…Ø©"), ln=True, align="R")

    pdf.set_font("Tajawal", size=11)
    pdf.cell(0, 8, ar("ØªÙ‚Ø±ÙŠØ± ØªÙ‚Ø¯ÙŠØ±ÙŠ Ø¢Ù„ÙŠ (Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø±Ø³Ù…ÙŠ)"), ln=True, align="R")

    pdf.ln(4)

    # Body fields
    pdf.set_font("Tajawal", size=12)
    for k, v in report.items():
        pdf.multi_cell(0, 8, ar(f"{k}: {v}"), align="R")

    # QR
    pdf.image(tmp.name, x=165, y=250, w=35, h=35)
    pdf.set_font("Tajawal", size=9)
    pdf.set_xy(10, 288)
    pdf.cell(0, 6, ar("QR Ù„Ù„ØªØ­Ù‚Ù‚: " + verify_url), align="R")

    # Page 2: Model Card
    pdf.add_page()
    pdf.add_font("Tajawal", "", FONT_PATH, uni=True)
    pdf.set_font("Tajawal", size=16)
    pdf.cell(0, 10, ar("Model Card â€“ Ù…Ù†Ù‡Ø¬ÙŠØ© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"), ln=True, align="R")
    pdf.ln(2)
    pdf.set_font("Tajawal", size=12)

    model_card_lines = [
        "Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: Gradient Boosting Regressor",
        "Ø§Ù„Ù†Ø·Ø§Ù‚: Ù…Ø¯ÙŠÙ†Ø© Ù…ÙƒØ© Ø§Ù„Ù…ÙƒØ±Ù…Ø© ÙÙ‚Ø·",
        "Ø§Ù„Ù‡Ø¯Ù: ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø³Ù†ÙˆÙŠØ© Ù„Ù„Ø¹Ù‚Ø§Ø± Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙÙ‚Ø§Øª",
        "Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª (Features): Ø§Ù„Ù…Ø³Ø§Ø­Ø©ØŒ Ø®Ø· Ø§Ù„Ø¹Ø±Ø¶ØŒ Ø®Ø· Ø§Ù„Ø·ÙˆÙ„ØŒ Ø§Ù„Ù…Ø³Ø§ÙØ© Ù„Ù„Ø­Ø±Ù… (ÙƒÙ…)",
        "Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª: Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø³Ù†ÙˆÙŠØ© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (Ø±ÙŠØ§Ù„)",
        "Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: RÂ² Ù„Ù‚ÙŠØ§Ø³ Ø¬ÙˆØ¯Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ (ÙƒÙ„Ù…Ø§ Ø§Ù‚ØªØ±Ø¨ Ù…Ù† 1 ÙƒØ§Ù† Ø£ÙØ¶Ù„)",
        "Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:",
        "- Ø§Ù„ØªÙ‚Ø±ÙŠØ± ØªÙ‚Ø¯ÙŠØ±ÙŠ Ø¢Ù„ÙŠ ÙˆÙ„Ø§ ÙŠÙØ¹Ø¯ Ø§Ø¹ØªÙ…Ø§Ø¯Ù‹Ø§ Ù†Ù‡Ø§Ø¦ÙŠÙ‹Ø§",
        "- ÙŠØªØ£Ø«Ø± Ø¨Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¹Ø¯Ø¯ Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø©",
        "- ÙŠÙØ³ØªØ®Ø¯Ù… ÙƒØ£Ø¯Ø§Ø© Ø¯Ø¹Ù… Ù‚Ø±Ø§Ø± ÙˆÙ„ÙŠØ³ Ø¨Ø¯ÙŠÙ„Ù‹Ø§ Ø¹Ù† Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø±Ø³Ù…ÙŠ",
    ]
    for line in model_card_lines:
        pdf.multi_cell(0, 8, ar(line), align="R")

    out = pdf.output(dest="S").encode("latin-1")
    return out

# =========================
# APP
# =========================
st.markdown(f"""
<h1 style="text-align:center">
ğŸ›ï¸ Ù…Ù†ØµØ© <span class="gold">Ø¥Ø³ØªØ¯Ø§Ù…Ø©</span><br>
Ù…Ø¯ÙŠÙ†Ø© Ù…ÙƒØ© Ø§Ù„Ù…ÙƒØ±Ù…Ø©
</h1>
<p style="text-align:center; color:#666">
Ù†Ø³Ø®Ø© Ø­ÙƒÙˆÙ…ÙŠØ© â€“ ØªØ´ØºÙŠÙ„ Ø¹Ø¨Ø± Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¨Ø¯ÙˆÙ† Google Sheets)
</p>
""", unsafe_allow_html=True)

with st.container():
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.subheader("ğŸ“¤ Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    up = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù Excel Ø£Ùˆ CSV ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙÙ‚Ø§Øª", type=["xlsx", "xls", "csv"])

    st.caption("Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: latitude, longitude, Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø³Ù†ÙˆÙŠØ©, Ø§Ù„Ù…Ø³Ø§Ø­Ø©, Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©")

    if not up:
        st.info("Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¨Ø¯Ø¡.")
        st.stop()

    try:
        if up.name.lower().endswith(".csv"):
            raw = pd.read_csv(up)
        else:
            raw = pd.read_excel(up)

        data = clean_df(raw)

        if data.empty:
            st.error("Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙÙ‚Ø§Øª Ù„Ù…ÙƒØ© Ø§Ù„Ù…ÙƒØ±Ù…Ø© ÙÙŠ Ø§Ù„Ù…Ù„Ù Ø£Ùˆ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ø§Ù‚ØµØ©/ØºÙŠØ± ØµØ­ÙŠØ­Ø©.")
            st.stop()

    except Exception as e:
        st.error(f"ØªØ¹Ø°Ø± Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ø£Ùˆ ØªÙ†Ø¸ÙŠÙÙ‡: {e}")
        st.stop()
    st.markdown("</div>", unsafe_allow_html=True)

# Train once
model, model_r2 = train_model(data)

tab1, tab2, tab3 = st.tabs(["ğŸ¯ Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…", "ğŸ—ºï¸ Ø§Ù„Ø®Ø±ÙŠØ·Ø©", "ğŸ“Š Ø¨Ù†Ùƒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"])

with tab1:
    c1, c2 = st.columns([1, 1.2], gap="large")

    with c1:
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.subheader("ğŸ§¾ Ù…ÙˆØ§ØµÙØ§Øª Ø§Ù„Ø¹Ù‚Ø§Ø± Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù")
        target_area = st.number_input("Ø§Ù„Ù…Ø³Ø§Ø­Ø© (Ù…Â²)", min_value=1, value=500)

        st.write("ğŸ“Œ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ø¥Ø¯Ø®Ø§Ù„ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø§Ù„Ø¹Ù‚Ø§Ø± Ù„Ø²ÙŠØ§Ø¯Ø© Ø¯Ù‚Ø© Ù‚Ø±Ø¨ Ø§Ù„Ø­Ø±Ù…")
        use_loc = st.checkbox("Ø³Ø£Ø¯Ø®Ù„ Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª", value=False)
        if use_loc:
            target_lat = st.number_input("Latitude", value=float(data["lat"].mean()), format="%.6f")
            target_lon = st.number_input("Longitude", value=float(data["lon"].mean()), format="%.6f")
        else:
            target_lat = float(data["lat"].mean())
            target_lon = float(data["lon"].mean())

        if st.button("Ø¥ØµØ¯Ø§Ø± ØªÙ‚Ø±ÙŠØ± Ø­ÙƒÙˆÙ…ÙŠ"):
            target_dist = float(haversine_km(target_lat, target_lon, HARAM_LAT, HARAM_LON))

            pred = float(model.predict([[target_area, target_lat, target_lon, target_dist]])[0])

            similar = data[data["area"].between(target_area * 0.8, target_area * 1.2)]
            conf_label, conf_score = gov_confidence(int(len(similar)), model_r2)

            rid = make_report_id()
            verify_url = f"https://verify.estidama.sa/{rid}"

            report = {
                "Ø±Ù‚Ù… Ø§Ù„ØªÙ‚Ø±ÙŠØ±": rid,
                "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©": CITY_NAME,
                "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥ØµØ¯Ø§Ø±": datetime.now().strftime("%Y-%m-%d"),
                "Ø§Ù„Ù…Ø³Ø§Ø­Ø©": f"{target_area} Ù…Â²",
                "Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø³Ù†ÙˆÙŠØ© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (ML)": f"{pred:,.0f} Ø±ÙŠØ§Ù„",
                "Ù‚Ø±Ø¨ Ø§Ù„Ø­Ø±Ù…": f"{target_dist:.2f} ÙƒÙ…",
                "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø­ÙƒÙˆÙ…ÙŠ": f"{conf_label} ({conf_score}/100)",
                "Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ RÂ²": f"{model_r2:.2f}",
                "Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙ‚Ø§Øª (Ù…ÙƒØ©)": int(len(data)),
                "Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø© (Ù…Ø³Ø§Ø­Ø©)": int(len(similar)),
            }

            pdf_bytes = build_pdf_report(report, verify_url)

            with c2:
                st.markdown('<div class="card">', unsafe_allow_html=True)
                st.subheader("âœ… Ù†ØªØ§Ø¦Ø¬ ÙÙˆØ±ÙŠØ©")
                st.metric("Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø³Ù†ÙˆÙŠØ© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (ML)", f"{pred:,.0f} Ø±ÙŠØ§Ù„")
                st.metric("Ù‚Ø±Ø¨ Ø§Ù„Ø­Ø±Ù…", f"{target_dist:.2f} ÙƒÙ…")
                st.metric("Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø­ÙƒÙˆÙ…ÙŠ", conf_label)
                st.progress(conf_score / 100)
                st.caption(f"RÂ²: {model_r2:.2f} | ØµÙÙ‚Ø§Øª Ù…Ø´Ø§Ø¨Ù‡Ø©: {len(similar)}")
                st.download_button(
                    "â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± PDF",
                    data=pdf_bytes,
                    file_name=f"{rid}.pdf",
                    mime="application/pdf",
                )
                st.markdown("</div>", unsafe_allow_html=True)

        st.markdown("</div>", unsafe_allow_html=True)

with tab2:
    st.subheader("ğŸ—ºï¸ Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØµÙÙ‚Ø§Øª Ø¯Ø§Ø®Ù„ Ù…ÙƒØ©")
    view = pdk.ViewState(
        latitude=float(data["lat"].mean()),
        longitude=float(data["lon"].mean()),
        zoom=12,
        pitch=45,
    )

    layer = pdk.Layer(
        "ScatterplotLayer",
        data=data,
        get_position="[lon, lat]",
        get_radius=90,
        get_fill_color=[255, 180, 0, 140],
        pickable=True,
    )

    st.pydeck_chart(pdk.Deck(layers=[layer], initial_view_state=view, tooltip={"text": "Ø§Ù„Ù‚ÙŠÙ…Ø©: {Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø³Ù†ÙˆÙŠØ©}\nØ§Ù„Ù…Ø³Ø§Ø­Ø©: {Ø§Ù„Ù…Ø³Ø§Ø­Ø©}"}))

with tab3:
    st.subheader("ğŸ“Š Ø¨Ù†Ùƒ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙƒØ©")
    st.dataframe(data.drop(columns=["lat", "lon", "price", "area"], errors="ignore"), use_container_width=True)

st.markdown("<hr><center>Ø¥Ø³ØªØ¯Ø§Ù…Ø© | ØªØ·ÙˆÙŠØ±: Ù…Ø­Ù…Ø¯ Ø¯Ø§ØºØ³ØªØ§Ù†ÙŠ Â© 2026</center>", unsafe_allow_html=True)
